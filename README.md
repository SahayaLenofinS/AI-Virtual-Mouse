# AI-Virtual-Mouse
This project utilizes computer vision and hand tracking to create a virtual mouse control system. It allows users to control the mouse cursor using hand gestures captured from a webcam feed. The system detects hand movements, maps them to screen coordinates, and translates specific gestures into mouse actions, such as cursor movement and clicking. Additionally, it provides real-time feedback on the frame rate of the video feed.

The main features of this virtual mouse control system:

Hand Tracking: Utilizes computer vision techniques to detect and track the user's hand movements in real-time.

Cursor Movement: Maps hand movements to screen coordinates, enabling users to control the mouse cursor by moving their hand.

Gesture Recognition: Recognizes specific hand gestures, such as extending the index finger, to activate cursor movement mode.

Clicking Functionality: Detects gestures, like extending both the index and middle fingers close together, to perform mouse clicks.

Frame Rate Display: Provides real-time feedback on the frame rate of the webcam feed, ensuring smooth performance.

User Feedback: Visual indicators, such as drawing circles at the fingertip and clicking positions, provide users with feedback on their hand gestures and actions.

Customizable Settings: Parameters such as frame reduction and cursor movement smoothing can be adjusted to fine-tune the user experience.

These features collectively enable users to interact with their computer using intuitive hand gestures, offering an alternative input method for individuals with mobility challenges or those seeking a hands-free computing experience.
